{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**BRICKKI BRICKS AND THE FORGERS**\n",
    "\n",
    "It’s your first day at your new job as head of quality\n",
    "control for Brickki, a company that specializes in\n",
    "producing high-quality building blocks of all shapes and\n",
    "sizes (Figure 4-1).\n",
    "\n",
    "You are immediately alerted to a problem with some of\n",
    "the items coming off the production line. A competitor\n",
    "has started to make counterfeit copies of Brickki bricks\n",
    "and has found a way to mix them into the bags received\n",
    "by your customers. You decide to become an expert at\n",
    "telling the difference between the counterfeit bricks and\n",
    "the real thing, so that you can intercept the forged\n",
    "bricks on the production line before they are given to\n",
    "customers. Over time, by listening to customer\n",
    "feedback, you gradually become more adept at spotting\n",
    "the fakes.\n",
    "\n",
    "The forgers are not happy about this—they react to your\n",
    "improved detection abilities by making some changes to their forgery process so that now, the difference\n",
    "between the real bricks and the fakes is even harder for\n",
    "you to spot.\n",
    "\n",
    "Not one to give up, you retrain yourself to identify the\n",
    "more sophisticated fakes and try to keep one step ahead\n",
    "of the forgers. This process continues, with the forgers\n",
    "iteratively updating their brick creation technologies\n",
    "while you try to become increasingly more accomplished\n",
    "at intercepting their fakes.\n",
    "\n",
    "With every week that passes, it becomes more and more\n",
    "difficult to tell the difference between the real Brickki\n",
    "bricks and those created by the forgers. It seems that\n",
    "this simple game of cat and mouse is enough to drive\n",
    "significant improvement in both the quality of the\n",
    "forgery and the quality of the detection.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A GAN is a battle between two adversaries, the generator\n",
    "and the discriminator. The generator tries to convert\n",
    "random noise into observations that look as if they have\n",
    "been sampled from the original dataset, and the\n",
    "discriminator tries to predict whether an observation\n",
    "comes from the original dataset or is one of the generator’s\n",
    "forgeries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import utils, layers, losses, metrics, models, optimizers,callbacks\n",
    "import tensorflow as tf\n",
    "from utils import display, sample_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = 'C:\\\\Users\\\\Whitebox\\\\Desktop\\\\envs_and_git_repos\\\\generative_models\\\\data\\\\lego bricks\\\\dataset'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = utils.image_dataset_from_directory(\n",
    "                                        folder\n",
    "                                        ,labels=None\n",
    "                                        ,color_mode='grayscale'\n",
    "                                        ,image_size=(64,64)\n",
    "                                        ,batch_size=128\n",
    "                                        ,shuffle=True\n",
    "                                        ,seed=42\n",
    "                                        ,interpolation='bilinear'\n",
    "                                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(img):\n",
    " img = (tf.cast(img, \"float32\") - 127.5) / 127.5\n",
    " return img\n",
    "train = train_data.map(lambda x: preprocess(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The Discriminator\n",
    "The goal of the discriminator is to predict if an image is\n",
    "real or fake. This is a supervised image classification\n",
    "problem, so we can use a similar architecture to those we\n",
    "worked with in Chapter 2: stacked convolutional layers,\n",
    "with a single output node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "KERNEL_SIZE = 4\n",
    "FEATURE_SIZE = 64\n",
    "STRIDES = 2\n",
    "CHANNELS=1\n",
    "IMG_SIZE = 64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Keras model that defines the discriminator—a model\n",
    "that takes an input image and outputs a single number\n",
    "between 0 and 1\n",
    "\n",
    "Flatten the last convolutional layer—by this point, the\n",
    "shape of the tensor is 1 × 1 × 1, so there is no need for a\n",
    "final Dense layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator_input = layers.Input(shape=(IMG_SIZE,IMG_SIZE,CHANNELS), name='discriminator_input')\n",
    "x = layers.Conv2D(filters=FEATURE_SIZE, kernel_size=KERNEL_SIZE, padding='same',strides=STRIDES,use_bias=False)(discriminator_input)\n",
    "x = layers.LeakyReLU(.2)(x)\n",
    "x = layers.Dropout(0.3)(x)\n",
    "\n",
    "x = layers.Conv2D(filters=FEATURE_SIZE*2, kernel_size=KERNEL_SIZE, padding='same',strides=STRIDES,use_bias=False)(x)\n",
    "x = layers.BatchNormalization(momentum=0.9)(x)\n",
    "x = layers.LeakyReLU(.2)(x)\n",
    "x = layers.Dropout(0.3)(x)\n",
    "\n",
    "x = layers.Conv2D(filters=FEATURE_SIZE*4, kernel_size=KERNEL_SIZE, padding='same',strides=STRIDES,use_bias=False)(x)\n",
    "x = layers.BatchNormalization(momentum=0.9)(x)\n",
    "x = layers.LeakyReLU(.2)(x)\n",
    "x = layers.Dropout(0.3)(x)\n",
    "\n",
    "x = layers.Conv2D(filters=FEATURE_SIZE*8, kernel_size=KERNEL_SIZE, padding='same',strides=STRIDES,use_bias=False)(x)\n",
    "x = layers.BatchNormalization(momentum=0.9)(x)\n",
    "x = layers.LeakyReLU(.2)(x)\n",
    "x = layers.Dropout(0.3)(x)\n",
    "\n",
    "x = layers.Conv2D(filters=1, kernel_size=KERNEL_SIZE, padding='valid',strides=1,activation='sigmoid',use_bias=False)(x)\n",
    "discriminator_output = layers.Flatten()(x)\n",
    "\n",
    "discriminator = models.Model(discriminator_input,discriminator_output)\n",
    "discriminator.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generator\n",
    "The input to the generator\n",
    "will be a vector drawn from a multivariate standard normal\n",
    "distribution. The output is an image of the same size as an\n",
    "image in the original training data\n",
    "\n",
    "This description may remind you of the decoder in a\n",
    "variational autoencoder. In fact, the generator of a GAN\n",
    "fulfills exactly the same purpose as the decoder of a VAE:\n",
    "converting a vector in the latent space to an image. The\n",
    "concept of mapping from a latent space back to the original\n",
    "domain is very common in generative modeling, as it gives\n",
    "us the ability to manipulate vectors in the latent space to\n",
    "change high-level features of images in the original domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z_DIM = 100\n",
    "EPOCHS=300\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice how we use a stride of 2 in some of the\n",
    "Conv2DTranspose layers to increase the spatial shape of the\n",
    "tensor as it passes through the network (1 in the original\n",
    "vector, then 4, 8, 16, 32, and finally 64), while decreasing\n",
    "the number of channels (512 then 256, 128, 64, and finally\n",
    "1 to match the grayscale output).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator_input = layers.Input(shape=(Z_DIM,), name='generator_input')\n",
    "x = layers.Reshape(target_shape=(1,1,Z_DIM))(generator_input)\n",
    "x = layers.Conv2DTranspose(filters=512, kernel_size=KERNEL_SIZE,padding='valid',strides=1,use_bias=False)(x)\n",
    "x = layers.BatchNormalization(momentum=0.9)(x)\n",
    "x = layers.LeakyReLU(0.2)(x)\n",
    "\n",
    "x = layers.Conv2DTranspose(filters=256, kernel_size=KERNEL_SIZE,padding='same',strides=STRIDES,use_bias=False)(x)\n",
    "x = layers.BatchNormalization(momentum=0.9)(x)\n",
    "x = layers.LeakyReLU(0.2)(x)\n",
    "\n",
    "x = layers.Conv2DTranspose(filters=128, kernel_size=KERNEL_SIZE,padding='same',strides=STRIDES,use_bias=False)(x)\n",
    "x = layers.BatchNormalization(momentum=0.9)(x)\n",
    "x = layers.LeakyReLU(0.2)(x)\n",
    "\n",
    "x = layers.Conv2DTranspose(filters=64, kernel_size=KERNEL_SIZE,padding='same',strides=STRIDES,use_bias=False)(x)\n",
    "x = layers.BatchNormalization(momentum=0.9)(x)\n",
    "x = layers.LeakyReLU(0.2)(x)\n",
    "\n",
    "generator_output = layers.Conv2DTranspose(filters=1, kernel_size=4,padding='same',\n",
    "                    strides=STRIDES,activation='tanh',use_bias=False)(x)\n",
    "generator = models.Model(generator_input,generator_output)\n",
    "generator.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training the DCGAN\n",
    "\n",
    "The key to understanding GANs lies in\n",
    "understanding the training process for the generator and\n",
    "discriminator\n",
    "\n",
    "- We can train the discriminator by creating a training set\n",
    "where some of the images are real observations from the\n",
    "training set and some are fake outputs from the generator.\n",
    "We then treat this as a supervised learning problem, where\n",
    "the labels are 1 for the real images and 0 for the fake\n",
    "images, with binary cross-entropy as the loss function.\n",
    "- How should we train the generator? We need to find a way\n",
    "of scoring each generated image so that it can optimize\n",
    "toward high-scoring images. Luckily, we have a\n",
    "discriminator that does exactly that! We can generate a\n",
    "batch of images and pass these through the discriminator\n",
    "to get a score for each image. The loss function for the\n",
    "generator is then simply the binary cross-entropy between\n",
    "these probabilities and a vector of ones, because we want\n",
    "to train the generator to produce images that the\n",
    "discriminator thinks are real.\n",
    "- Crucially, we must alternate the training of these two\n",
    "networks, making sure that we only update the weights of\n",
    "one network at a time. For example, during the generator\n",
    "training process, only the generator’s weights are updated.\n",
    "If we allowed the discriminator’s weights to change as well,\n",
    "the discriminator would just adjust so that it is more likely\n",
    "to predict the generated images to be real, which is not the\n",
    "desired outcome. We want generated images to be\n",
    "predicted close to 1 (real) because the generator is strong,\n",
    "not because the discriminator is weak.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DCGAN(models.Model):\n",
    "    def __init__(self, discriminator, generator,latent_dim):\n",
    "        super(DCGAN,self).__init__()\n",
    "        self.discriminator = discriminator\n",
    "        self.generator = generator\n",
    "        self.latent_dim = latent_dim\n",
    "    \n",
    "    def compile(self, d_optimizer, g_optimizer):\n",
    "        super(DCGAN,self).compile()\n",
    "        self.loss_fn = losses.BinaryCrossentropy()\n",
    "        self.d_optimizer = d_optimizer\n",
    "        self.g_optimizer = g_optimizer\n",
    "        self.d_loss_metric = metrics.Mean(name='d_loss')\n",
    "        self.g_loss_metric = metrics.Mean(name='g_loss')\n",
    "\n",
    "\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return [self.d_loss_metric,self.g_loss_metric]\n",
    "\n",
    "    def train_step(self,real_images):\n",
    "        batch_size = tf.shape(real_images)[0]\n",
    "        random_latent_vectors = tf.random.normal(shape=(batch_size,self.latent_dim))\n",
    "\n",
    "        with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
    "            generated_images = self.generator(random_latent_vectors,training=True)\n",
    "            real_predictions = self.discriminator(real_images,training=True)\n",
    "            fake_predictions = self.discriminator(generated_images,training=True)\n",
    "            real_labels = tf.ones_like(real_predictions)\n",
    "            real_noisy_labels = real_labels + 0.1 * tf.random.uniform(tf.shape(real_predictions))\n",
    "            fake_labels = tf.zeros_like(fake_predictions)\n",
    "            fake_noisy_labels = fake_labels + 0.1 * tf.random.uniform(tf.shape(fake_predictions))\n",
    "\n",
    "            d_real_loss= self.loss_fn(real_noisy_labels,real_predictions)\n",
    "            d_fake_loss = self.loss_fn(fake_noisy_labels,fake_predictions)\n",
    "            d_loss = (d_real_loss + d_fake_loss)/2.0\n",
    "\n",
    "            g_loss = self.loss_fn(real_labels,fake_predictions)\n",
    "\n",
    "        gradient_of_discriminator = disc_tape.gradient(d_loss,self.discriminator.trainable_variables)\n",
    "        gradient_of_generator = gen_tape.gradient(g_loss,self.generator.trainable_variables)\n",
    "\n",
    "        self.d_optimizer.apply_gradients(zip(gradient_of_discriminator,self.discriminator.trainable_variables))\n",
    "        self.g_optimizer.apply_gradients(zip(gradient_of_generator,self.generator.trainable_variables))\n",
    "\n",
    "        self.d_loss_metric.update_state(d_loss)\n",
    "        self.g_loss_metric.update_state(g_loss)\n",
    "\n",
    "        return  {m.name: m.result() for m in self.metrics}\n",
    "\n",
    "dcgan = DCGAN(discriminator,generator,latent_dim=Z_DIM)\n",
    "dcgan.compile(d_optimizer = optimizers.Adam(learning_rate=0.0002,beta_1=0.5,beta_2=0.999),\n",
    "              g_optimizer = optimizers.Adam(learning_rate=0.0002,beta_1=0.5,beta_2=0.999))    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a model save checkpoint\n",
    "model_checkpoint_callback = callbacks.ModelCheckpoint(\n",
    "    filepath=\"./checkpoint/checkpoint.ckpt\",\n",
    "    save_weights_only=True,\n",
    "    save_freq=\"epoch\",\n",
    "    verbose=0,\n",
    ")\n",
    "\n",
    "tensorboard_callback = callbacks.TensorBoard(log_dir=\"./logs\")\n",
    "\n",
    "\n",
    "class ImageGenerator(callbacks.Callback):\n",
    "    def __init__(self, num_img, latent_dim):\n",
    "        self.num_img = num_img\n",
    "        self.latent_dim = latent_dim\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        random_latent_vectors = tf.random.normal(\n",
    "            shape=(self.num_img, self.latent_dim)\n",
    "        )\n",
    "        generated_images = self.model.generator(random_latent_vectors)\n",
    "        generated_images = generated_images * 127.5 + 127.5\n",
    "        generated_images = generated_images.numpy()\n",
    "        display(\n",
    "            generated_images,\n",
    "            save_to=\"./dcgan_output/generated_img_%03d.png\" % (epoch),\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dcgan.fit(\n",
    "    train,\n",
    "    epochs=EPOCHS,\n",
    "    callbacks=[\n",
    "        model_checkpoint_callback,\n",
    "        tensorboard_callback,\n",
    "        ImageGenerator(num_img=10, latent_dim=Z_DIM),\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the final models\n",
    "generator.save(\"./models/generator\")\n",
    "discriminator.save(\"./models/discriminator\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate New Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample some points in the latent space, from the standard normal distribution\n",
    "grid_width, grid_height = (10, 3)\n",
    "z_sample = np.random.normal(size=(grid_width * grid_height, Z_DIM))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reconstructions = generator.predict(z_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draw a plot of decoded images\n",
    "fig = plt.figure(figsize=(18, 5))\n",
    "fig.subplots_adjust(hspace=0.4, wspace=0.4)\n",
    "\n",
    "# Output the grid of faces\n",
    "for i in range(grid_width * grid_height):\n",
    "    ax = fig.add_subplot(grid_height, grid_width, i + 1)\n",
    "    ax.axis(\"off\")\n",
    "    ax.imshow(reconstructions[i, :, :], cmap=\"Greys\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_images(img1, img2):\n",
    "    return np.mean(np.abs(img1 - img2))\n",
    "\n",
    "all_data = []\n",
    "for i in train.as_numpy_iterator():\n",
    "    all_data.extend(i)\n",
    "all_data = np.array(all_data)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r, c = 3, 5\n",
    "fig, axs = plt.subplots(r, c, figsize=(10, 6))\n",
    "fig.suptitle(\"Generated images\", fontsize=20)\n",
    "\n",
    "noise = np.random.normal(size=(r * c, Z_DIM))\n",
    "gen_imgs = generator.predict(noise)\n",
    "\n",
    "cnt = 0\n",
    "for i in range(r):\n",
    "    for j in range(c):\n",
    "        axs[i, j].imshow(gen_imgs[cnt], cmap=\"gray_r\")\n",
    "        axs[i, j].axis(\"off\")\n",
    "        cnt += 1\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(r, c, figsize=(10, 6))\n",
    "fig.suptitle(\"Closest images in the training set\", fontsize=20)\n",
    "\n",
    "cnt = 0\n",
    "for i in range(r):\n",
    "    for j in range(c):\n",
    "        c_diff = 99999\n",
    "        c_img = None\n",
    "        for k_idx, k in enumerate(all_data):\n",
    "            diff = compare_images(gen_imgs[cnt], k)\n",
    "            if diff < c_diff:\n",
    "                c_img = np.copy(k)\n",
    "                c_diff = diff\n",
    "        axs[i, j].imshow(c_img, cmap=\"gray_r\")\n",
    "        axs[i, j].axis(\"off\")\n",
    "        cnt += 1\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Discriminator overpowers the generator**\n",
    "\n",
    "If the discriminator becomes too strong, the signal from the\n",
    "loss function becomes too weak to drive any meaningful\n",
    "improvements in the generator. In the worst-case scenario,\n",
    "the discriminator perfectly learns to separate real images\n",
    "from fake images and the gradients vanish completely,\n",
    "leading to no training whatsoever\n",
    "\n",
    "If you find your discriminator loss function collapsing, you\n",
    "need to find ways to weaken the discriminator. Try the\n",
    "following suggestions:\n",
    "- Increase the rate parameter of the Dropout layers in\n",
    "the discriminator to dampen the amount of information\n",
    "that flows through the network.\n",
    "- Reduce the learning rate of the discriminator.\n",
    "- Reduce the number of convolutional filters in the\n",
    "discriminator.\n",
    "- Add noise to the labels when training the discriminator.\n",
    "Flip the labels of some images at random when training\n",
    "the discriminator."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Generator overpowers the discriminator**\n",
    "\n",
    "If the discriminator is not powerful enough, the generator\n",
    "will find ways to easily trick the discriminator with a small\n",
    "sample of nearly identical images. This is known as mode\n",
    "collapse.\n",
    "\n",
    "For example, suppose we were to train the generator over\n",
    "several batches without updating the discriminator in\n",
    "between. The generator would be inclined to find a single\n",
    "observation (also known as a mode) that always fools the\n",
    "discriminator and would start to map every point in the\n",
    "latent input space to this image. Moreover, the gradients of\n",
    "the loss function would collapse to near 0, so it wouldn’t be\n",
    "able to recover from this state.\n",
    "\n",
    "Even if we then tried to retrain the discriminator to stop it\n",
    "being fooled by this one point, the generator would simply\n",
    "find another mode that fools the discriminator, since it has\n",
    "already become numb to its input and therefore has no\n",
    "incentive to diversify its output.\n",
    "The effect of mode collapse can be seen in Figure 4-10\n",
    "\n",
    "If you find that your generator is suffering from mode\n",
    "collapse, you can try strengthening the discriminator using\n",
    "the opposite suggestions to those listed in the previous\n",
    "section. Also, you can try reducing the learning rate of both\n",
    "networks and increasing the batch size.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Uninformative loss**\n",
    "\n",
    "Since the deep learning model is compiled to minimize the\n",
    "loss function, it would be natural to think that the smaller\n",
    "the loss function of the generator, the better the quality of\n",
    "the images produced. However, since the generator is only\n",
    "graded against the current discriminator and the\n",
    "discriminator is constantly improving, we cannot compare\n",
    "the loss function evaluated at different points in the\n",
    "training process. Indeed, in Figure 4-6, the loss function of\n",
    "the generator actually increases over time, even though the\n",
    "quality of the images is clearly improving. This lack of correlation between the generator loss and image quality\n",
    "sometimes makes GAN training difficult to monitor.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wasserstein GAN with Gradient Penalty (WGAN-GP)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
